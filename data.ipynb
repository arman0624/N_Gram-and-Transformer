{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T19:55:30.143790Z",
     "start_time": "2024-03-17T19:55:29.565706Z"
    }
   },
   "id": "1e0e873bf29b190e",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-17T19:55:47.309816Z",
     "start_time": "2024-03-17T19:55:47.305501Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def load_text_file(file_path: str) -> List[str]:\n",
    "    \"\"\"Reads a text file and returns a list of lines.\"\"\"\n",
    "    print(f\"Loading text file from {file_path}...\")\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return [line.strip() for line in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading text file from data/lm_data/treebank-sentences-train.txt...\n",
      "Loading text file from data/lm_data/treebank-sentences-test.txt...\n",
      "Loading text file from data/lm_data/treebank-sentences-dev.txt...\n"
     ]
    }
   ],
   "source": [
    "train = load_text_file('data/lm_data/treebank-sentences-train.txt')\n",
    "test = load_text_file('data/lm_data/treebank-sentences-test.txt')\n",
    "dev = load_text_file('data/lm_data/treebank-sentences-dev.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T19:56:15.001448Z",
     "start_time": "2024-03-17T19:56:14.980046Z"
    }
   },
   "id": "d53e5cf1c17f8eaa",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 36261 sentences\n",
      "Dev: 4529 sentences\n",
      "Test: 4554 sentences\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {len(train)} sentences\")\n",
    "print(f\"Dev: {len(dev)} sentences\")\n",
    "print(f\"Test: {len(test)} sentences\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T19:56:56.500449Z",
     "start_time": "2024-03-17T19:56:56.496995Z"
    }
   },
   "id": "4555aa63f4a71352",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_num_unique_tokens(sentences: List[str]) -> int:\n",
    "    \"\"\"Returns the number of unique tokens in a list of sentences.\"\"\"\n",
    "    tokens = set()\n",
    "    for sentence in sentences:\n",
    "        tokens.update(sentence.split())\n",
    "    return len(tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T19:58:09.424185Z",
     "start_time": "2024-03-17T19:58:09.421277Z"
    }
   },
   "id": "e57f9469d6e23218",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 32215 unique tokens\n",
      "Dev: 11005 unique tokens\n",
      "Test: 10483 unique tokens\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {get_num_unique_tokens(train)} unique tokens\")\n",
    "print(f\"Dev: {get_num_unique_tokens(dev)} unique tokens\")\n",
    "print(f\"Test: {get_num_unique_tokens(test)} unique tokens\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T19:58:09.715527Z",
     "start_time": "2024-03-17T19:58:09.629387Z"
    }
   },
   "id": "355f261d8de1a26",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_sentence_avg_length(sentences: List[str]) -> float:\n",
    "    \"\"\"Returns the average length of sentences in a list of sentences.\"\"\"\n",
    "    total_length = 0\n",
    "    for sentence in sentences:\n",
    "        total_length += len(sentence.split())\n",
    "    return total_length / len(sentences)\n",
    "def get_sentence_max_length(sentences: List[str]) -> int:\n",
    "    \"\"\"Returns the maximum length of sentences in a list of sentences.\"\"\"\n",
    "    max_length = 0\n",
    "    for sentence in sentences:\n",
    "        max_length = max(max_length, len(sentence.split()))\n",
    "    return max_length\n",
    "\n",
    "def get_sentence_min_length(sentences: List[str]) -> int:\n",
    "    \"\"\"Returns the minimum length of sentences in a list of sentences.\"\"\"\n",
    "    min_length = 100000\n",
    "    for sentence in sentences:\n",
    "        min_length = min(min_length, len(sentence.split()))\n",
    "    return min_length   \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T20:02:43.446125Z",
     "start_time": "2024-03-17T20:02:43.442228Z"
    }
   },
   "id": "97a32af5d52e46ee",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: avg length: 20.799260913929565, max length: 39\n",
      "Dev: avg length: 20.705453742548023, max length: 39\n",
      "Test: avg length: 20.691699604743082, max length: 39\n",
      "Train: min length: 1\n",
      "Dev: min length: 1\n",
      "Test: min length: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: avg length: {get_sentence_avg_length(train)}, max length: {get_sentence_max_length(train)}\")\n",
    "print(f\"Dev: avg length: {get_sentence_avg_length(dev)}, max length: {get_sentence_max_length(dev)}\")\n",
    "print(f\"Test: avg length: {get_sentence_avg_length(test)}, max length: {get_sentence_max_length(test)}\")\n",
    "print(f\"Train: min length: {get_sentence_min_length(train)}\")\n",
    "print(f\"Dev: min length: {get_sentence_min_length(dev)}\")\n",
    "print(f\"Test: min length: {get_sentence_min_length(test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T20:02:43.693553Z",
     "start_time": "2024-03-17T20:02:43.580693Z"
    }
   },
   "id": "63196bcc77627459",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def most_common_tokens(sentences: List[str], n: int) -> pd.DataFrame:\n",
    "    \"\"\"Returns a dataframe with the n most common tokens in a list of sentences.\"\"\"\n",
    "    tokens = {}\n",
    "    for sentence in sentences:\n",
    "        for token in sentence.split():\n",
    "            if token in tokens:\n",
    "                tokens[token] += 1\n",
    "            else:\n",
    "                tokens[token] = 1\n",
    "    tokens = pd.DataFrame(tokens.items(), columns=['token', 'count'])\n",
    "    return tokens.sort_values('count', ascending=False).head(n)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T20:03:50.641054Z",
     "start_time": "2024-03-17T20:03:50.637412Z"
    }
   },
   "id": "f9b0cd5c89a49afd",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    token  count\n",
      "8     the  34134\n",
      "20     of  18792\n",
      "50     to  18284\n",
      "11      a  16016\n",
      "31    and  14130\n",
      "102    in  12584\n",
      "116    's   7841\n",
      "185   for   6709\n",
      "84   that   6673\n",
      "71    The   6204\n"
     ]
    }
   ],
   "source": [
    "print(most_common_tokens(train, 10))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T20:03:50.936192Z",
     "start_time": "2024-03-17T20:03:50.757687Z"
    }
   },
   "id": "6d2556137819ecc7",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def mode_length(sentences: List[str]) -> int:\n",
    "    \"\"\"Returns the mode length of sentences in a list of sentences.\"\"\"\n",
    "    lengths = {}\n",
    "    for sentence in sentences:\n",
    "        length = len(sentence.split())\n",
    "        if length in lengths:\n",
    "            lengths[length] += 1\n",
    "        else:\n",
    "            lengths[length] = 1\n",
    "    return max(lengths, key=lengths.get)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T20:04:37.816909Z",
     "start_time": "2024-03-17T20:04:37.813426Z"
    }
   },
   "id": "131d40c92ee13412",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: mode length: 20\n",
      "Dev: mode length: 23\n",
      "Test: mode length: 19\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: mode length: {mode_length(train)}\")\n",
    "print(f\"Dev: mode length: {mode_length(dev)}\")\n",
    "print(f\"Test: mode length: {mode_length(test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T20:04:42.103796Z",
     "start_time": "2024-03-17T20:04:42.065497Z"
    }
   },
   "id": "6daaccf7edfc95b0",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def most_common_tokens(sentences: List[str], n: int) -> pd.DataFrame:\n",
    "    \"\"\"Returns a dataframe with the n most common tokens in a list of sentences.\"\"\"\n",
    "    tokens = {}\n",
    "    for sentence in sentences:\n",
    "        for token in sentence.split():\n",
    "            if token in tokens:\n",
    "                tokens[token] += 1\n",
    "            else:\n",
    "                tokens[token] = 1\n",
    "    tokens = pd.DataFrame(tokens.items(), columns=['token', 'count'])\n",
    "    return tokens.sort_values('count', ascending=False).head(n)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T20:05:18.610304Z",
     "start_time": "2024-03-17T20:05:18.606793Z"
    }
   },
   "id": "c6e2741554506003",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:   token  count\n",
      "8   the  34134\n",
      "Dev:    token  count\n",
      "10   the   4264\n",
      "Test:    token  count\n",
      "55   the   4400\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {most_common_tokens(train, 1)}\")\n",
    "print(f\"Dev: {most_common_tokens(dev, 1)}\")\n",
    "print(f\"Test: {most_common_tokens(test, 1)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T20:05:38.486986Z",
     "start_time": "2024-03-17T20:05:38.308070Z"
    }
   },
   "id": "918d3d0be45b2a64",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ed33055b28d73b3a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
